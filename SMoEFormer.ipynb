{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWoVO-zNRrZp"
      },
      "source": [
        "# Package installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5eWpMGYBNhR",
        "outputId": "570675ac-34de-44bf-90e2-194986e29e65"
      },
      "outputs": [],
      "source": [
        "#!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "#!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "#!pip install torch-geometric\n",
        "#!pip install ogb  # for datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJeY9fPpAD0Y",
        "outputId": "e8c85cad-71e2-4649-b1b3-783e18355e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /home/kg798/miniconda3/lib/python3.11/site-packages (3.0.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install cython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzkGB0BFSHTK"
      },
      "source": [
        "# Data piepline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdbqSi00R23n"
      },
      "source": [
        "## use cython to accelerate data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0kh5xAXBOFh",
        "outputId": "638b24a4-5c71-4ad0-f4e1-3ab47d6c1faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cython extension is already loaded. To reload it, use:\n",
            "  %reload_ext cython\n"
          ]
        }
      ],
      "source": [
        "%load_ext cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zt8W5rvMAD6t"
      },
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "import cython\n",
        "from cython.parallel cimport prange, parallel\n",
        "cimport numpy\n",
        "import numpy\n",
        "\n",
        "def floyd_warshall(adjacency_matrix):\n",
        "\n",
        "    (nrows, ncols) = adjacency_matrix.shape\n",
        "    assert nrows == ncols\n",
        "    cdef unsigned int n = nrows\n",
        "\n",
        "    adj_mat_copy = adjacency_matrix.astype(long, order='C', casting='safe', copy=True)\n",
        "    assert adj_mat_copy.flags['C_CONTIGUOUS']\n",
        "    cdef numpy.ndarray[long, ndim=2, mode='c'] M = adj_mat_copy\n",
        "    cdef numpy.ndarray[long, ndim=2, mode='c'] path = numpy.zeros([n, n], dtype=numpy.int64)\n",
        "\n",
        "    cdef unsigned int i, j, k\n",
        "    cdef long M_ij, M_ik, cost_ikkj\n",
        "    cdef long* M_ptr = &M[0,0]\n",
        "    cdef long* M_i_ptr\n",
        "    cdef long* M_k_ptr\n",
        "\n",
        "    # set unreachable nodes distance to 510\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                M[i][j] = 0\n",
        "            elif M[i][j] == 0:\n",
        "                M[i][j] = 510\n",
        "\n",
        "    # floyed algo\n",
        "    for k in range(n):\n",
        "        M_k_ptr = M_ptr + n*k\n",
        "        for i in range(n):\n",
        "            M_i_ptr = M_ptr + n*i\n",
        "            M_ik = M_i_ptr[k]\n",
        "            for j in range(n):\n",
        "                cost_ikkj = M_ik + M_k_ptr[j]\n",
        "                M_ij = M_i_ptr[j]\n",
        "                if M_ij > cost_ikkj:\n",
        "                    M_i_ptr[j] = cost_ikkj\n",
        "                    path[i][j] = k\n",
        "\n",
        "    # set unreachable path to 510\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if M[i][j] >= 510:\n",
        "                path[i][j] = 510\n",
        "                M[i][j] = 510\n",
        "\n",
        "    return M, path\n",
        "\n",
        "\n",
        "def get_all_edges(path, i, j):\n",
        "    cdef unsigned int k = path[i][j]\n",
        "    if k == 0:\n",
        "        return []\n",
        "    else:\n",
        "        return get_all_edges(path, i, k) + [k] + get_all_edges(path, k, j)\n",
        "\n",
        "\n",
        "def gen_edge_input(max_dist, path, edge_feat):\n",
        "\n",
        "    (nrows, ncols) = path.shape\n",
        "    assert nrows == ncols\n",
        "    cdef unsigned int n = nrows\n",
        "    cdef unsigned int max_dist_copy = max_dist\n",
        "\n",
        "    path_copy = path.astype(long, order='C', casting='safe', copy=True)\n",
        "    edge_feat_copy = edge_feat.astype(long, order='C', casting='safe', copy=True)\n",
        "    assert path_copy.flags['C_CONTIGUOUS']\n",
        "    assert edge_feat_copy.flags['C_CONTIGUOUS']\n",
        "\n",
        "    cdef numpy.ndarray[long, ndim=4, mode='c'] edge_fea_all = -1 * numpy.ones([n, n, max_dist_copy, edge_feat.shape[-1]], dtype=numpy.int64)\n",
        "    cdef unsigned int i, j, k, num_path, cur\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                continue\n",
        "            if path_copy[i][j] == 510:\n",
        "                continue\n",
        "            # if path_copy[i][j] == 0:\n",
        "            #     continue\n",
        "            path = [i] + get_all_edges(path_copy, i, j) + [j]\n",
        "            # path = [i] + [j]\n",
        "            num_path = len(path) - 1\n",
        "            for k in range(num_path):\n",
        "                edge_fea_all[i, j, k, :] = edge_feat_copy[path[k], path[k+1], :]\n",
        "\n",
        "    return edge_fea_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLqOoiftSFDl"
      },
      "source": [
        "## Some utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "m8EDGXoUBdIq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def convert_to_single_emb(x, offset=512):\n",
        "    # for Graphormer\n",
        "    feature_num = x.size(1) if len(x.size()) > 1 else 1\n",
        "    feature_offset = 1 + torch.arange(0, feature_num * offset, offset, dtype=torch.long)\n",
        "    x = x + feature_offset\n",
        "    return x\n",
        "\n",
        "\n",
        "def preprocess_item(item):\n",
        "    # for Graphormer\n",
        "    edge_attr, edge_index, x = item.edge_attr, item.edge_index, item.x\n",
        "\n",
        "    N = x.size(0)\n",
        "    x = convert_to_single_emb(x)\n",
        "\n",
        "    # node adj matrix [N, N] bool\n",
        "    adj = torch.zeros([N, N], dtype=torch.bool)\n",
        "    adj[edge_index[0, :], edge_index[1, :]] = True\n",
        "\n",
        "    # edge feature here\n",
        "    if len(edge_attr.size()) == 1:\n",
        "        edge_attr = edge_attr[:, None]\n",
        "    attn_edge_type = torch.zeros([N, N, edge_attr.size(-1)], dtype=torch.long)\n",
        "    attn_edge_type[edge_index[0, :], edge_index[1, :]] = (\n",
        "        convert_to_single_emb(edge_attr) + 1\n",
        "    )\n",
        "\n",
        "    shortest_path_result, path = floyd_warshall(adj.numpy())\n",
        "    max_dist = np.amax(shortest_path_result)\n",
        "    # max_dist = 1\n",
        "    edge_input = gen_edge_input(max_dist, path, attn_edge_type.numpy())\n",
        "    # edge_input = algos.gen_edge_input(max_dist, adj.numpy(), attn_edge_type.numpy())\n",
        "    rel_pos = torch.from_numpy((shortest_path_result)).long()\n",
        "    # rel_pos = torch.from_numpy((adj.numpy())).long()\n",
        "    attn_bias = torch.zeros([N + 1, N + 1], dtype=torch.float)  # with graph token\n",
        "\n",
        "    # combine\n",
        "    item.x = x\n",
        "    item.edge_attr = edge_attr\n",
        "    item.adj = adj\n",
        "    item.attn_bias = attn_bias\n",
        "    item.attn_edge_type = attn_edge_type\n",
        "    item.rel_pos = rel_pos\n",
        "    item.in_degree = adj.long().sum(dim=1).view(-1)\n",
        "    item.out_degree = adj.long().sum(dim=0).view(-1)\n",
        "    item.edge_input = torch.from_numpy(edge_input).long()\n",
        "    item.edge_index = edge_index\n",
        "\n",
        "    return item\n",
        "\n",
        "\n",
        "def pad_1d_unsqueeze(x, padlen):\n",
        "    x = x + 1  # pad id = 0\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen], dtype=x.dtype)\n",
        "        new_x[:xlen] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_2d_unsqueeze(x, padlen):\n",
        "    x = x + 1  # pad id = 0\n",
        "    xlen, xdim = x.size()\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, xdim], dtype=x.dtype)\n",
        "        new_x[:xlen, :] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_attn_bias_unsqueeze(x, padlen):\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, padlen], dtype=x.dtype).fill_(float(\"-inf\"))\n",
        "        new_x[:xlen, :xlen] = x\n",
        "        new_x[xlen:, :xlen] = 0\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_edge_type_unsqueeze(x, padlen):\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, padlen, x.size(-1)], dtype=x.dtype)\n",
        "        new_x[:xlen, :xlen, :] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_rel_pos_unsqueeze(x, padlen):\n",
        "    x = x + 1\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, padlen], dtype=x.dtype)\n",
        "        new_x[:xlen, :xlen] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_3d_unsqueeze(x, padlen1, padlen2, padlen3):\n",
        "    x = x + 1\n",
        "    xlen1, xlen2, xlen3, xlen4 = x.size()\n",
        "    if xlen1 < padlen1 or xlen2 < padlen2 or xlen3 < padlen3:\n",
        "        new_x = x.new_zeros([padlen1, padlen2, padlen3, xlen4], dtype=x.dtype)\n",
        "        new_x[:xlen1, :xlen2, :xlen3, :] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "class Batch:\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_bias,\n",
        "        attn_edge_type,\n",
        "        rel_pos,\n",
        "        in_degree,\n",
        "        out_degree,\n",
        "        x,\n",
        "        edge_input,\n",
        "        edge_index,\n",
        "        edge_attr,\n",
        "        y,\n",
        "    ):\n",
        "        super(Batch, self).__init__()\n",
        "        # self.idx = idx\n",
        "        self.in_degree, self.out_degree = in_degree, out_degree\n",
        "        self.x, self.y = x, y\n",
        "        self.attn_bias, self.attn_edge_type, self.rel_pos = (\n",
        "            attn_bias,\n",
        "            attn_edge_type,\n",
        "            rel_pos,\n",
        "        )\n",
        "        self.edge_input = edge_input\n",
        "        self.dataset_idx = None\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_attr = edge_attr\n",
        "\n",
        "    def to(self, device):\n",
        "        # self.idx = self.idx.to(device)\n",
        "        self.in_degree, self.out_degree = self.in_degree.to(device), self.out_degree.to(\n",
        "            device\n",
        "        )\n",
        "        self.x, self.y = self.x.to(device), self.y.to(device)\n",
        "        self.attn_bias, self.attn_edge_type, self.rel_pos = (\n",
        "            self.attn_bias.to(device),\n",
        "            self.attn_edge_type.to(device),\n",
        "            self.rel_pos.to(device),\n",
        "        )\n",
        "        self.edge_input = self.edge_input.to(device)\n",
        "        self.edge_index = self.edge_index.to(device)\n",
        "        self.edge_attr = self.edge_attr.to(device)\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.in_degree.size(0)\n",
        "\n",
        "\n",
        "def collator(items, max_node=512, multi_hop_max_dist=20, rel_pos_max=20):\n",
        "    items = [item for item in items if item is not None and item.x.size(0) <= max_node]\n",
        "    if len(items) == 0:\n",
        "        return None\n",
        "    items = [\n",
        "        (\n",
        "            item.attn_bias,\n",
        "            item.attn_edge_type,\n",
        "            item.rel_pos,\n",
        "            item.in_degree,\n",
        "            item.out_degree,\n",
        "            item.x,\n",
        "            item.edge_input[:, :, :multi_hop_max_dist, :],\n",
        "            item.edge_index,\n",
        "            item.edge_attr,\n",
        "            item.y,\n",
        "        )\n",
        "        for item in items\n",
        "    ]\n",
        "    (\n",
        "        attn_biases,\n",
        "        attn_edge_types,\n",
        "        rel_poses,\n",
        "        in_degrees,\n",
        "        out_degrees,\n",
        "        xs,\n",
        "        edge_inputs,\n",
        "        edge_index,\n",
        "        edge_attr,\n",
        "        ys,\n",
        "    ) = zip(*items)\n",
        "\n",
        "    for idx, _ in enumerate(attn_biases):\n",
        "        attn_biases[idx][1:, 1:][rel_poses[idx] >= rel_pos_max] = float(\"-inf\")\n",
        "    max_node_num = max(i.size(0) for i in xs)\n",
        "    max_dist = max(i.size(-2) for i in edge_inputs)\n",
        "    y = torch.cat(ys)\n",
        "    x = torch.cat([pad_2d_unsqueeze(i, max_node_num) for i in xs])\n",
        "    edge_input = torch.cat(\n",
        "        [pad_3d_unsqueeze(i, max_node_num, max_node_num, max_dist) for i in edge_inputs]\n",
        "    )\n",
        "    attn_bias = torch.cat(\n",
        "        [pad_attn_bias_unsqueeze(i, max_node_num + 1) for i in attn_biases]\n",
        "    )\n",
        "    attn_edge_type = torch.cat(\n",
        "        [pad_edge_type_unsqueeze(i, max_node_num) for i in attn_edge_types]\n",
        "    )\n",
        "    rel_pos = torch.cat([pad_rel_pos_unsqueeze(i, max_node_num) for i in rel_poses])\n",
        "    in_degree = torch.cat([pad_1d_unsqueeze(i, max_node_num) for i in in_degrees])\n",
        "    out_degree = torch.cat([pad_1d_unsqueeze(i, max_node_num) for i in out_degrees])\n",
        "    edge_indices = [item[7] for item in items]\n",
        "    cum_node_count = 0\n",
        "    for idx, edge_index in enumerate(edge_indices):\n",
        "        num_nodes = xs[idx].size(0)  # 当前图的节点数\n",
        "        # 偏移 edge_index\n",
        "        edge_indices[idx] = edge_index + cum_node_count\n",
        "        cum_node_count += num_nodes\n",
        "\n",
        "    # ADD: edge_index & edge_attrs\n",
        "    edge_index = torch.cat(edge_indices, dim=1)\n",
        "    edge_attr = torch.cat(edge_attr, dim=0)\n",
        "    \"\"\"\n",
        "    print(\"Debug in collator:\")\n",
        "    for idx, edge_index in enumerate(edge_indices):\n",
        "        print(f\"Graph {idx}: Edge index min: {edge_index.min()}, max: {edge_index.max()}\")\n",
        "\n",
        "    print(f\"Combined edge index shape: {edge_index.shape}\")\n",
        "    print(f\"Combined edge index min: {edge_index.min()}, max: {edge_index.max()}\")\n",
        "    \"\"\"\n",
        "    return Batch(\n",
        "        # idx=torch.LongTensor(idxs),\n",
        "        attn_bias=attn_bias,\n",
        "        attn_edge_type=attn_edge_type,\n",
        "        rel_pos=rel_pos,\n",
        "        in_degree=in_degree,\n",
        "        out_degree=out_degree,\n",
        "        x=x,\n",
        "        edge_input=edge_input,\n",
        "        edge_index=edge_index,\n",
        "        edge_attr=edge_attr,\n",
        "        y=y,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMyBLdcSSVNJ"
      },
      "source": [
        "## Dataset+Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "v6Y_IvN2BdK8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GraphormerDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "\n",
        "        self.num = len(dataset)\n",
        "        self.dataset = dataset\n",
        "        self.indices = torch.arange(self.num)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # directly return the sampled graph\n",
        "        sampled_graph = self.dataset[self.indices[item]]\n",
        "        return preprocess_item(sampled_graph)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num\n",
        "\n",
        "    def shuffle(self):\n",
        "        rand = torch.randperm(self.num)\n",
        "        self.indices = self.indices[rand]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "10Ies1JKBdNR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from copy import deepcopy\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "class GraphormerDataLoader(DataLoader):\n",
        "    def __init__(self, dataset, **kwargs):\n",
        "\n",
        "        self.dataset = GraphormerDataset(dataset)\n",
        "        self.collator = partial(collator, max_node=128, multi_hop_max_dist=5, rel_pos_max=1024)\n",
        "\n",
        "        kwargs[\"collate_fn\"] = self.__collate_fn__\n",
        "        super().__init__(dataset=self.dataset, **kwargs)\n",
        "\n",
        "    def __collate_fn__(self, batch):\n",
        "        batch_graphs = batch\n",
        "        batch_graphs = self.collator(batch_graphs)\n",
        "        return batch_graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P91QUX7eS2zd"
      },
      "source": [
        "# Model implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MoE Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.distributions.normal import Normal\n",
        "\n",
        "\n",
        "class SparseDispatcher(object):\n",
        "    def __init__(self, num_experts, gates):\n",
        "        \"\"\"Create a SparseDispatcher.\"\"\"\n",
        "\n",
        "        self._gates = gates\n",
        "        self._num_experts = num_experts\n",
        "        # sort experts\n",
        "        sorted_experts, index_sorted_experts = torch.nonzero(gates).sort(0)\n",
        "        # drop indices\n",
        "        _, self._expert_index = sorted_experts.split(1, dim=1)\n",
        "        # get according batch index for each expert\n",
        "        self._batch_index = torch.nonzero(gates)[index_sorted_experts[:, 1], 0]\n",
        "        # calculate num samples that each expert gets\n",
        "        self._part_sizes = (gates > 0).sum(0).tolist()\n",
        "        # expand gates to match with self._batch_index\n",
        "        gates_exp = gates[self._batch_index.flatten()]\n",
        "        self._nonzero_gates = torch.gather(gates_exp, 1, self._expert_index)\n",
        "\n",
        "    def dispatch(self, inp, edge_index, edge_attr):\n",
        "        \"\"\"Create one input Tensor for each expert.\n",
        "        The `Tensor` for a expert `i` contains the slices of `inp` corresponding\n",
        "        to the batch elements `b` where `gates[b, i] > 0`.\n",
        "        Args:\n",
        "          inp: a `Tensor` of shape \"[batch_size, <extra_input_dims>]`\n",
        "        Returns:\n",
        "          a list of `num_experts` `Tensor`s with shapes\n",
        "            `[expert_batch_size_i, <extra_input_dims>]`.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # expand according to batch index so we can just split by _part_sizes\n",
        "        inp_exp = inp[self._batch_index].squeeze(1)\n",
        "        edge_index_exp = edge_index[:, self._batch_index]\n",
        "        edge_attr_exp = edge_attr[self._batch_index]\n",
        "        return (\n",
        "            torch.split(inp_exp, self._part_sizes, dim=0),\n",
        "            torch.split(edge_index_exp, self._part_sizes, dim=1),\n",
        "            torch.split(edge_attr_exp, self._part_sizes, dim=0),\n",
        "        )\n",
        "\n",
        "    def combine(self, expert_out, multiply_by_gates=True):\n",
        "        \"\"\"Sum together the expert output, weighted by the gates.\n",
        "        The slice corresponding to a particular batch element `b` is computed\n",
        "        as the sum over all experts `i` of the expert output, weighted by the\n",
        "        corresponding gate values.  If `multiply_by_gates` is set to False, the\n",
        "        gate values are ignored.\n",
        "        Args:\n",
        "          expert_out: a list of `num_experts` `Tensor`s, each with shape\n",
        "            `[expert_batch_size_i, <extra_output_dims>]`.\n",
        "          multiply_by_gates: a boolean\n",
        "        Returns:\n",
        "          a `Tensor` with shape `[batch_size, <extra_output_dims>]`.\n",
        "        \"\"\"\n",
        "        # apply exp to expert outputs, so we are not longer in log space\n",
        "        stitched = torch.cat(expert_out, 0).exp()\n",
        "\n",
        "        if multiply_by_gates:\n",
        "            stitched = stitched.mul(self._nonzero_gates)\n",
        "        zeros = torch.zeros(\n",
        "            self._gates.size(0),\n",
        "            expert_out[-1].size(1),\n",
        "            requires_grad=True,\n",
        "            device=stitched.device,\n",
        "        )\n",
        "        # combine samples that have been processed by the same k experts\n",
        "        combined = zeros.index_add(0, self._batch_index, stitched.float())\n",
        "        # add eps to all zero values in order to avoid nans when going back to log space\n",
        "        combined[combined == 0] = np.finfo(float).eps\n",
        "        # back to log space\n",
        "        return combined.log()\n",
        "\n",
        "    def expert_to_gates(self):\n",
        "        \"\"\"Gate values corresponding to the examples in the per-expert `Tensor`s.\n",
        "        Returns:\n",
        "          a list of `num_experts` one-dimensional `Tensor`s with type `tf.float32`\n",
        "              and shapes `[expert_batch_size_i]`\n",
        "        \"\"\"\n",
        "        # split nonzero gates for each expert\n",
        "        return torch.split(self._nonzero_gates, self._part_sizes, dim=0)\n",
        "\n",
        "\n",
        "class MoE(torch.nn.Module):\n",
        "\n",
        "    \"\"\"Call a Sparsely gated mixture of experts layer with 1-layer Feed-Forward networks as experts.\n",
        "    Args:\n",
        "    input_size: integer - size of the input\n",
        "    output_size: integer - size of the input\n",
        "    num_experts: an integer - number of experts\n",
        "    hidden_size: an integer - hidden size of the experts\n",
        "    noisy_gating: a boolean\n",
        "    k: an integer - how many experts to use for each batch element\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        output_size,\n",
        "        num_experts,\n",
        "        experts_conv,\n",
        "        experts_bn,\n",
        "        noisy_gating=True,\n",
        "        k=4,\n",
        "        coef=1e-2,\n",
        "        num_experts_1hop=None,\n",
        "    ):\n",
        "        super(MoE, self).__init__()\n",
        "        self.noisy_gating = noisy_gating\n",
        "        self.num_experts = num_experts\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.k = k\n",
        "        self.loss_coef = coef\n",
        "        if not num_experts_1hop:\n",
        "            self.num_experts_1hop = (\n",
        "                num_experts  # by default, all experts are hop-1 experts.\n",
        "            )\n",
        "        else:\n",
        "            assert num_experts_1hop <= num_experts\n",
        "            self.num_experts_1hop = num_experts_1hop\n",
        "        # instantiate experts\n",
        "        # self.experts = nn.ModuleList([MLP(self.input_size, self.output_size, self.hidden_size) for i in range(self.num_experts)])\n",
        "        self.experts_conv = experts_conv\n",
        "        self.experts_bn = experts_bn\n",
        "        self.w_gate = torch.nn.Parameter(\n",
        "            torch.zeros(input_size, num_experts), requires_grad=True\n",
        "        )\n",
        "        self.w_noise = torch.nn.Parameter(\n",
        "            torch.zeros(input_size, num_experts), requires_grad=True\n",
        "        )\n",
        "\n",
        "        self.softplus = torch.nn.Softplus()\n",
        "        self.softmax = torch.nn.Softmax(1)\n",
        "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
        "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
        "        assert self.k <= self.num_experts\n",
        "        # print(\"MoE prepared\")\n",
        "\n",
        "    def cv_squared(self, x):\n",
        "        \"\"\"The squared coefficient of variation of a sample.\n",
        "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
        "        Epsilons added for numerical stability.\n",
        "        Returns 0 for an empty Tensor.\n",
        "        Args:\n",
        "        x: a `Tensor`.\n",
        "        Returns:\n",
        "        a `Scalar`.\n",
        "        \"\"\"\n",
        "        eps = 1e-10\n",
        "        # if only num_experts = 1\n",
        "\n",
        "        if x.shape[0] == 1:\n",
        "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
        "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
        "\n",
        "    def _gates_to_load(self, gates):\n",
        "        \"\"\"Compute the true load per expert, given the gates.\n",
        "        The load is the number of examples for which the corresponding gate is >0.\n",
        "        Args:\n",
        "        gates: a `Tensor` of shape [batch_size, n]\n",
        "        Returns:\n",
        "        a float32 `Tensor` of shape [n]\n",
        "        \"\"\"\n",
        "        return (gates > 0).sum(0)\n",
        "\n",
        "    def _prob_in_top_k(\n",
        "        self, clean_values, noisy_values, noise_stddev, noisy_top_values\n",
        "    ):\n",
        "        \"\"\"Helper function to NoisyTopKGating.\n",
        "        Computes the probability that value is in top k, given different random noise.\n",
        "        This gives us a way of backpropagating from a loss that balances the number\n",
        "        of times each expert is in the top k experts per example.\n",
        "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
        "        not be differentiable.\n",
        "        Args:\n",
        "        clean_values: a `Tensor` of shape [batch, n].\n",
        "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
        "          normally distributed noise with standard deviation noise_stddev.\n",
        "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
        "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
        "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
        "        Returns:\n",
        "        a `Tensor` of shape [batch, n].\n",
        "        \"\"\"\n",
        "        # The number of experts in the top-k group.\n",
        "        k = noisy_top_values.size(1)\n",
        "\n",
        "        # Calculate the difference between noisy values and the k-th noisy top value.\n",
        "        difference = noisy_top_values[:, k - 1 : k].unsqueeze(\n",
        "            2\n",
        "        ) - noisy_values.unsqueeze(1)\n",
        "        # Compute the cumulative probability of this difference being positive\n",
        "        prob = torch.sigmoid(difference / noise_stddev)\n",
        "\n",
        "        return prob.mean(dim=1)\n",
        "\n",
        "    def noisy_top_k_gating(self, x, train, noise_epsilon=1e-2):\n",
        "        \"\"\"Noisy top-k gating.\n",
        "        See paper: https://arxiv.org/abs/1701.06538.\n",
        "        Args:\n",
        "          x: input Tensor with shape [batch_size, input_size]\n",
        "          train: a boolean - we only add noise at training time.\n",
        "          noise_epsilon: a float\n",
        "        Returns:\n",
        "          gates: a Tensor with shape [batch_size, num_experts]\n",
        "          load: a Tensor with shape [num_experts]\n",
        "        \"\"\"\n",
        "        clean_logits = x @ self.w_gate\n",
        "        # print(\"x in noisy gate:\", x.shape)\n",
        "        # print(\"gate:\", self.w_gate.shape)\n",
        "        if self.noisy_gating and train:\n",
        "            raw_noise_stddev = x @ self.w_noise\n",
        "            noise_stddev = self.softplus(raw_noise_stddev) + noise_epsilon\n",
        "            noisy_logits = clean_logits + (\n",
        "                torch.randn_like(clean_logits) * noise_stddev\n",
        "            )\n",
        "            logits = noisy_logits\n",
        "        else:\n",
        "            logits = clean_logits\n",
        "\n",
        "        # calculate topk + 1 that will be needed for the noisy gates\n",
        "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
        "        top_k_logits = top_logits[:, : self.k]\n",
        "        top_k_indices = top_indices[:, : self.k]\n",
        "        top_k_gates = self.softmax(top_k_logits)\n",
        "\n",
        "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
        "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
        "\n",
        "        if self.noisy_gating and self.k < self.num_experts and train:\n",
        "            load = (\n",
        "                self._prob_in_top_k(\n",
        "                    clean_logits, noisy_logits, noise_stddev, top_logits\n",
        "                )\n",
        "            ).sum(0)\n",
        "        else:\n",
        "            load = self._gates_to_load(gates)\n",
        "        return gates, load\n",
        "\n",
        "    def forward(\n",
        "        self, x, edge_index, edge_attr, edge_index_2hop=None, edge_attr_2hop=None\n",
        "    ):\n",
        "        \"\"\"Args:\n",
        "        x: tensor shape [batch_size, input_size]\n",
        "        train: a boolean scalar.\n",
        "        loss_coef: a scalar - multiplier on load-balancing losses\n",
        "\n",
        "        Returns:\n",
        "        y: a tensor with shape [batch_size, output_size].\n",
        "        extra_training_loss: a scalar.  This should be added into the overall\n",
        "        training loss of the model.  The backpropagation of this loss\n",
        "        encourages all experts to be approximately equally used across a batch.\n",
        "        \"\"\"\n",
        "        # print(\"MoE forward start\")\n",
        "        gates, load = self.noisy_top_k_gating(x, self.training)\n",
        "        # calculate importance loss\n",
        "        importance = gates.sum(0)\n",
        "        #\n",
        "        loss = self.cv_squared(importance) + self.cv_squared(load)\n",
        "        loss *= self.loss_coef\n",
        "\n",
        "        expert_outputs = []\n",
        "        \"\"\"\n",
        "        def adjust_edge_index_for_batch(edge_indices, batch_node_counts):\n",
        "            adjusted_edge_indices = []\n",
        "            node_offset = 0\n",
        "            for edge_index, node_count in zip(edge_indices, batch_node_counts):\n",
        "                adjusted_edge_index = edge_index.clone()\n",
        "                adjusted_edge_index[0, :] += node_offset\n",
        "                adjusted_edge_index[1, :] += node_offset\n",
        "                adjusted_edge_indices.append(adjusted_edge_index)\n",
        "\n",
        "                node_offset += node_count\n",
        "\n",
        "            return torch.cat(adjusted_edge_indices, dim=1)\n",
        "\n",
        "        adjusted_edge_index = adjust_edge_index_for_batch(\n",
        "            edge_index, batch_size=x.shape[0], num_nodes_per_graph=x.shape[1]\n",
        "        )\n",
        "        \"\"\"\n",
        "        # print(\"batch input size:\", x.size())\n",
        "        batch_size, num_nodes_per_graph, emb_dim = x.size()\n",
        "        x = x.view(batch_size * num_nodes_per_graph, emb_dim)\n",
        "        # print(\"prepare to forward to GIN\")\n",
        "        # print(\"edgedevice\", edge_index.device)\n",
        "        # print(\"attr device:\", edge_attr.device)\n",
        "        for i in range(self.num_experts):\n",
        "            if i < self.num_experts_1hop:\n",
        "                # print(f\"Expert {i}: x shape: {x.shape}, edge_index shape: {edge_index.shape}\")\n",
        "                # print(f\"Edge index min: {edge_index.min()}, max: {edge_index.max()}\")\n",
        "                expert_i_output = self.experts_conv[i](x, edge_index, edge_attr)\n",
        "            else:\n",
        "                expert_i_output = self.experts_conv[i](\n",
        "                    x, edge_index_2hop, edge_attr_2hop\n",
        "                )\n",
        "\n",
        "            expert_i_output = self.experts_bn[i](expert_i_output)\n",
        "            expert_i_output = expert_i_output.view(\n",
        "                batch_size, num_nodes_per_graph, emb_dim\n",
        "            )\n",
        "            # print(\"expert i output:\", expert_i_output.shape)\n",
        "            expert_outputs.append(expert_i_output)\n",
        "\n",
        "        expert_outputs = torch.stack(expert_outputs, dim=-1)\n",
        "        # print(\"expert_out_shape:\", expert_outputs.shape)\n",
        "        # print(\"Gate shape:\", gates.shape)\n",
        "\n",
        "        # gates: shape=[num_nodes, num_experts]\n",
        "        gates_expanded = gates.unsqueeze(2)\n",
        "        weighted_experts = gates_expanded * expert_outputs\n",
        "        y = weighted_experts.sum(dim=3)\n",
        "\n",
        "        return y, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph_Sparse_MoE_Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
        "\n",
        "\n",
        "class GINConv(MessagePassing):\n",
        "    def __init__(self, emb_dim):\n",
        "        \"\"\"\n",
        "        emb_dim (int): node embedding dimensionality\n",
        "        \"\"\"\n",
        "\n",
        "        super(GINConv, self).__init__(aggr=\"add\")\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(emb_dim, 2 * emb_dim),\n",
        "            torch.nn.BatchNorm1d(2 * emb_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(2 * emb_dim, emb_dim),\n",
        "        )\n",
        "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
        "        self.bond_encoder = BondEncoder(emb_dim=emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        #print(\"Debug in GINConv forward:\")\n",
        "        #print(f\"x shape: {x.shape}, edge_index shape: {edge_index.shape}\")\n",
        "        #print(f\"Edge index min: {edge_index.min()}, max: {edge_index.max()}\")\n",
        "        #print(f\"x min: {x.min()}, x max: {x.max()}\")\n",
        "        edge_embedding = self.bond_encoder(edge_attr)\n",
        "        out = self.mlp(\n",
        "            (1 + self.eps) * x\n",
        "            + self.propagate(edge_index, x=x, edge_attr=edge_embedding)\n",
        "        )\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_attr):\n",
        "        return F.relu(x_j + edge_attr)\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
        "\n",
        "\n",
        "class Sparse_MoE(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Output:\n",
        "        node representations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layer,\n",
        "        emb_dim,\n",
        "        num_experts=4,\n",
        "        drop_ratio=0.5,\n",
        "        JK=\"last\",\n",
        "        residual=False,\n",
        "        k=1,\n",
        "        coef=1e-2,\n",
        "        device=\"cpu\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        emb_dim (int): node embedding dimensionality\n",
        "        num_layer (int): number of GNN message passing layers\n",
        "        JK: Jumping knowledge refers to \"Representation Learning on Graphs with Jumping Knowledge Networks\"\n",
        "        k: k value for top-k sparse gating.\n",
        "        num_experts: total number of experts in each layer.\n",
        "        \"\"\"\n",
        "\n",
        "        super(Sparse_MoE, self).__init__()\n",
        "        self.num_layer = num_layer\n",
        "        self.num_experts = num_experts\n",
        "        self.k = k\n",
        "        self.drop_ratio = drop_ratio\n",
        "        self.JK = JK\n",
        "        ### add residual connection or not\n",
        "        self.residual = residual\n",
        "\n",
        "        print(\"SMoE got device:\", device)\n",
        "        self.emb_encoder = torch.nn.Embedding(\n",
        "            num_embeddings=1024, embedding_dim=emb_dim\n",
        "        ).to(device)\n",
        "\n",
        "        self.num_experts = num_experts\n",
        "\n",
        "        if self.num_layer < 2:\n",
        "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
        "\n",
        "        ###List of GNNs\n",
        "        self.ffns = torch.nn.ModuleList().to(device)\n",
        "\n",
        "        for layer in range(num_layer):\n",
        "            convs_list = torch.nn.ModuleList()\n",
        "            bn_list = torch.nn.ModuleList()\n",
        "            for expert_idx in range(num_experts):\n",
        "                convs_list.append(GINConv(emb_dim))\n",
        "                bn_list.append(torch.nn.BatchNorm1d(emb_dim))\n",
        "\n",
        "            \"\"\"\n",
        "            def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            output_size,\n",
        "            num_experts,\n",
        "            experts_conv,\n",
        "            experts_bn,\n",
        "            noisy_gating=True,\n",
        "            k=4,\n",
        "            coef=1e-2,\n",
        "            ):\n",
        "            \"\"\"\n",
        "\n",
        "            ffn = MoE(\n",
        "                input_size=emb_dim,\n",
        "                output_size=emb_dim,\n",
        "                num_experts=num_experts,\n",
        "                experts_conv=convs_list,\n",
        "                experts_bn=bn_list,\n",
        "                k=k,\n",
        "                coef=coef,\n",
        "            ).to(device)\n",
        "\n",
        "            self.ffns.append(ffn)\n",
        "            # self.check_model_device(ffn)\n",
        "\n",
        "        # self.mix_fn = lambda h_expert_list: torch.mean(torch.stack(h_expert_list, dim=0), dim=0)\n",
        "\n",
        "    def check_model_device(self, model):\n",
        "        param_list = []\n",
        "        for param in model.parameters():\n",
        "            param_list.append(param.device)\n",
        "        print(param_list)\n",
        "\n",
        "    def forward(self, batched_data, gformer_output):\n",
        "        # print(\"sparse_moe forward start\")\n",
        "        x, edge_index, edge_attr = (\n",
        "            batched_data.x,\n",
        "            batched_data.edge_index,\n",
        "            batched_data.edge_attr,\n",
        "        )\n",
        "        # print(\"SMoE Input Data Shape:\", x.shape)\n",
        "        # print(\"Edge Index Shape:\", edge_index.shape)\n",
        "        # print(\"Edge Attr Shape:\", edge_attr.shape)\n",
        "        # print(\"Edge attr:\", edge_attr)\n",
        "        # print(\"Smoe x device:\", x.device)\n",
        "        # print(\"Smoe edgeindex device:\", edge_index.device)\n",
        "        # print(\"Smoe edge_attr device:\", edge_attr.device)\n",
        "\n",
        "        ### computing input node embedding\n",
        "        # print([x[:,:,i].max().item(), x[:,:,i].min().item()] for i in range(x.size(2)))\n",
        "        embedded_features = [self.emb_encoder(x[:, :, i]) for i in range(x.size(2))]\n",
        "        # print(\"Emb_1_shape:\", embedded_features[0].shape)\n",
        "        # print(\"Emb_2_shape:\", embedded_features[1].shape)\n",
        "        # print(\"gformer_output_shape:\", gformer_output.shape)\n",
        "\n",
        "        global_token = gformer_output[:, 0, :].unsqueeze(1)\n",
        "        nodes_only = gformer_output[:, 1:, :]\n",
        "        modified_nodes = embedded_features[0] + embedded_features[1]\n",
        "        # embedded_x = torch.cat([global_token, modified_nodes], dim=1)\n",
        "        h_list = [modified_nodes]\n",
        "        # print(\"Initial h_list[0] shape:\", h_list[0].shape)\n",
        "        self.load_balance_loss = 0  # initialize load_balance_loss to 0 at the beginning of each forward pass.\n",
        "        # print(\"SMoE prepare end.\")\n",
        "        for layer in range(self.num_layer):\n",
        "            h, _layer_load_balance_loss = self.ffns[layer](\n",
        "                h_list[layer], edge_index, edge_attr, None, None\n",
        "            )\n",
        "            # print(f\"Layer {layer} Output Shape:\", h.shape)\n",
        "            self.load_balance_loss += _layer_load_balance_loss\n",
        "            # print(\"Smoe self-ffn done\")\n",
        "            if layer == self.num_layer - 1:\n",
        "                # remove relu for the last layer\n",
        "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
        "            else:\n",
        "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
        "\n",
        "            if self.residual:\n",
        "                h += h_list[layer]\n",
        "\n",
        "            h_list.append(h)\n",
        "\n",
        "        self.load_balance_loss /= self.num_layer\n",
        "        # print(\"Load Balance Loss after layer\", layer, \":\", _layer_load_balance_loss)\n",
        "\n",
        "        ### Different implementations of Jk-concat\n",
        "        if self.JK == \"last\":\n",
        "            node_representation = h_list[-1]\n",
        "        elif self.JK == \"sum\":\n",
        "            node_representation = 0\n",
        "            for layer in range(self.num_layer + 1):\n",
        "                node_representation += h_list[layer]\n",
        "        # print(\"Final Node Representation Shape:\", node_representation.shape)\n",
        "        # print(\"sparse_moe forward end\")\n",
        "        return node_representation, self.load_balance_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gZuzoDWSabW"
      },
      "source": [
        "## Graphormer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "wZKRKpzDBdPj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def init_bert_params(module, n_layers):\n",
        "    if isinstance(module, nn.Linear):\n",
        "        module.weight.data.normal_(mean=0.0, std=0.02 / math.sqrt(n_layers))\n",
        "        if module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "    if isinstance(module, nn.Embedding):\n",
        "        module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "\n",
        "\n",
        "class Graphormer(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_layers,\n",
        "        num_heads,\n",
        "        hidden_dim,\n",
        "        dropout_rate,\n",
        "        input_dropout_rate,\n",
        "        ffn_dim,\n",
        "        edge_type,\n",
        "        multi_hop_max_dist,\n",
        "        attention_dropout_rate,\n",
        "        moe_model,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # for simple feature\n",
        "        self.atom_encoder = nn.Embedding(512 * 2 + 1, hidden_dim, padding_idx=0)\n",
        "        self.edge_encoder = nn.Embedding(512 * 2 + 1, num_heads, padding_idx=0)\n",
        "\n",
        "        self.edge_type = edge_type\n",
        "        if self.edge_type == \"multi_hop\":\n",
        "            self.edge_dis_encoder = nn.Embedding(128 * num_heads * num_heads, 1)\n",
        "        self.rel_pos_encoder = nn.Embedding(512, num_heads, padding_idx=0)\n",
        "        self.in_degree_encoder = nn.Embedding(512, hidden_dim, padding_idx=0)\n",
        "        self.out_degree_encoder = nn.Embedding(512, hidden_dim, padding_idx=0)\n",
        "\n",
        "        self.input_dropout = nn.Dropout(input_dropout_rate)\n",
        "        encoders = [\n",
        "            EncoderLayer(\n",
        "                hidden_dim, ffn_dim, dropout_rate, attention_dropout_rate, num_heads\n",
        "            )\n",
        "            for _ in range(n_layers)\n",
        "        ]\n",
        "        self.layers = nn.ModuleList(encoders)\n",
        "        self.final_ln = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.graph_token = nn.Embedding(1, hidden_dim)\n",
        "        self.graph_token_virtual_distance = nn.Embedding(1, num_heads)\n",
        "\n",
        "        self.multi_hop_max_dist = multi_hop_max_dist\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.apply(lambda module: init_bert_params(module, n_layers=n_layers))\n",
        "\n",
        "        self.moe_layer = moe_model\n",
        "        # print(\"Gformer init end.\")\n",
        "\n",
        "    def forward(self, batched_data):\n",
        "        # print(\"Input Data Shape:\", batched_data.x.shape)\n",
        "        attn_bias, rel_pos, x = (\n",
        "            batched_data.attn_bias,\n",
        "            batched_data.rel_pos,\n",
        "            batched_data.x,\n",
        "        )\n",
        "        # print(\"Gformer_input_shape:\", x.shape)\n",
        "        in_degree, out_degree = batched_data.in_degree, batched_data.out_degree\n",
        "        edge_input, attn_edge_type = (\n",
        "            batched_data.edge_input,\n",
        "            batched_data.attn_edge_type,\n",
        "        )\n",
        "\n",
        "        # graph_attn_bias\n",
        "        n_graph, n_node = x.size()[:2]\n",
        "        graph_attn_bias = attn_bias.clone()\n",
        "        graph_attn_bias = graph_attn_bias.unsqueeze(1).repeat(\n",
        "            1, self.num_heads, 1, 1\n",
        "        )  # [n_graph, n_head, n_node+1, n_node+1]\n",
        "\n",
        "        # rel pos\n",
        "        # [n_graph, n_node, n_node, n_head] -> [n_graph, n_head, n_node, n_node]\n",
        "        rel_pos_bias = self.rel_pos_encoder(rel_pos).permute(0, 3, 1, 2)\n",
        "        # print(\"Rel Pos Bias Shape:\", rel_pos_bias.shape)\n",
        "        graph_attn_bias[:, :, 1:, 1:] = (\n",
        "            graph_attn_bias[:, :, 1:, 1:] + rel_pos_bias\n",
        "        )  # spatial encoder\n",
        "        # reset rel pos here\n",
        "        t = self.graph_token_virtual_distance.weight.view(1, self.num_heads, 1)\n",
        "        graph_attn_bias[:, :, 1:, 0] = graph_attn_bias[:, :, 1:, 0] + t\n",
        "        graph_attn_bias[:, :, 0, :] = graph_attn_bias[:, :, 0, :] + t\n",
        "\n",
        "        # edge feature\n",
        "        if self.edge_type == \"multi_hop\":\n",
        "            rel_pos_ = rel_pos.clone()\n",
        "            rel_pos_[rel_pos_ == 0] = 1  # set pad to 1\n",
        "            # set 1 to 1, x > 1 to x - 1\n",
        "            rel_pos_ = torch.where(rel_pos_ > 1, rel_pos_ - 1, rel_pos_)\n",
        "            if self.multi_hop_max_dist > 0:\n",
        "                rel_pos_ = rel_pos_.clamp(0, self.multi_hop_max_dist)\n",
        "                edge_input = edge_input[:, :, :, : self.multi_hop_max_dist, :]\n",
        "            # [n_graph, n_node, n_node, max_dist, n_head]\n",
        "            edge_input = self.edge_encoder(edge_input).mean(-2)\n",
        "            max_dist = edge_input.size(-2)\n",
        "            edge_input_flat = edge_input.permute(3, 0, 1, 2, 4).reshape(\n",
        "                max_dist, -1, self.num_heads\n",
        "            )\n",
        "            edge_input_flat = torch.bmm(\n",
        "                edge_input_flat,\n",
        "                self.edge_dis_encoder.weight.reshape(\n",
        "                    -1, self.num_heads, self.num_heads\n",
        "                )[:max_dist, :, :],\n",
        "            )\n",
        "            edge_input = edge_input_flat.reshape(\n",
        "                max_dist, n_graph, n_node, n_node, self.num_heads\n",
        "            ).permute(1, 2, 3, 0, 4)\n",
        "            edge_input = (\n",
        "                edge_input.sum(-2) / (rel_pos_.float().unsqueeze(-1))\n",
        "            ).permute(0, 3, 1, 2)\n",
        "            # print(\"Edge Input Shape:\", edge_input.shape)\n",
        "        else:\n",
        "            # [n_graph, n_node, n_node, n_head] -> [n_graph, n_head, n_node, n_node]\n",
        "            edge_input = self.edge_encoder(attn_edge_type).mean(-2).permute(0, 3, 1, 2)\n",
        "\n",
        "        graph_attn_bias[:, :, 1:, 1:] = (\n",
        "            graph_attn_bias[:, :, 1:, 1:] + edge_input\n",
        "        )  # edge encoder\n",
        "        graph_attn_bias = graph_attn_bias + attn_bias.unsqueeze(1)  # reset\n",
        "\n",
        "        # node feauture + graph token\n",
        "        node_feature = self.atom_encoder(x).sum(dim=-2)  # [n_graph, n_node, n_hidden]\n",
        "\n",
        "        node_feature = (\n",
        "            node_feature\n",
        "            + self.in_degree_encoder(in_degree)\n",
        "            + self.out_degree_encoder(out_degree)\n",
        "        )  # degree encoder\n",
        "        graph_token_feature = self.graph_token.weight.unsqueeze(0).repeat(n_graph, 1, 1)\n",
        "        graph_node_feature = torch.cat([graph_token_feature, node_feature], dim=1)\n",
        "        # print(\"Graph Node Feature Shape:\", graph_node_feature.shape)\n",
        "\n",
        "        # transfomrer encoder\n",
        "        output = self.input_dropout(graph_node_feature)\n",
        "        for enc_layer in self.layers:\n",
        "            output = enc_layer(output, attn_bias=graph_attn_bias)\n",
        "        # print(\"Gformer forward end -> to moe\")\n",
        "        # print(\"GFormer_out_Shape:\", output.shape)\n",
        "        # print(\"GFormer_batched_data:\",batched_data.shape)\n",
        "        moe_output, balance_loss = self.moe_layer(batched_data, output)\n",
        "        output = self.final_ln(output)\n",
        "\n",
        "        return moe_output, balance_loss\n",
        "\n",
        "\n",
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, hidden_size, ffn_size):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(hidden_size, ffn_size)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.layer2 = nn.Linear(ffn_size, hidden_size)\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, attention_dropout_rate, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.att_size = att_size = hidden_size // num_heads\n",
        "        self.scale = att_size**-0.5\n",
        "\n",
        "        self.linear_q = nn.Linear(hidden_size, num_heads * att_size)\n",
        "        self.linear_k = nn.Linear(hidden_size, num_heads * att_size)\n",
        "        self.linear_v = nn.Linear(hidden_size, num_heads * att_size)\n",
        "        self.att_dropout = nn.Dropout(attention_dropout_rate)\n",
        "\n",
        "        self.input_norm = nn.LayerNorm(hidden_size)\n",
        "        self.output_layer = nn.Linear(num_heads * att_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, attn_bias=None):\n",
        "        orig_q_size = x.size()\n",
        "\n",
        "        x = self.input_norm(x)\n",
        "\n",
        "        d_k = self.att_size\n",
        "        d_v = self.att_size\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # head_i = Attention(Q(W^Q)_i, K(W^K)_i, V(W^V)_i)\n",
        "        q = self.linear_q(x).view(batch_size, -1, self.num_heads, d_k)\n",
        "        k = self.linear_k(x).view(batch_size, -1, self.num_heads, d_k)\n",
        "        v = self.linear_v(x).view(batch_size, -1, self.num_heads, d_v)\n",
        "\n",
        "        q = q.transpose(1, 2)  # [b, h, q_len, d_k]\n",
        "        v = v.transpose(1, 2)  # [b, h, v_len, d_v]\n",
        "        k = k.transpose(1, 2).transpose(2, 3)  # [b, h, d_k, k_len]\n",
        "\n",
        "        # Scaled Dot-Product Attention.\n",
        "        # Attention(Q, K, V) = softmax((QK^T)/sqrt(d_k))V\n",
        "        q = q * self.scale\n",
        "        x = torch.matmul(q, k)  # [b, h, q_len, k_len]\n",
        "        if attn_bias is not None:\n",
        "            x = x + attn_bias\n",
        "\n",
        "        x = torch.softmax(x, dim=3)\n",
        "        x = self.att_dropout(x)\n",
        "        x = x.matmul(v)  # [b, h, q_len, attn]\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous()  # [b, q_len, h, attn]\n",
        "        x = x.view(batch_size, -1, self.num_heads * d_v)\n",
        "\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        assert x.size() == orig_q_size\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self, hidden_size, ffn_size, dropout_rate, attention_dropout_rate, num_heads\n",
        "    ):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(\n",
        "            hidden_size, attention_dropout_rate, num_heads\n",
        "        )\n",
        "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.ffn = FeedForwardNetwork(hidden_size, ffn_size)\n",
        "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x, attn_bias=None):\n",
        "        y = self.self_attn(x, attn_bias)\n",
        "        y = self.self_attention_dropout(y)\n",
        "        x1 = x + y\n",
        "        y = self.ffn(x1)\n",
        "        y = self.ffn_dropout(y)\n",
        "        return x1 + y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JMS0mwLSrnY"
      },
      "source": [
        "## Decoder for graph-level class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "5rf4wuJbCSgc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention\n",
        "from torch_geometric.nn.aggr import Set2Set\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.inits import uniform\n",
        "\n",
        "from torch_scatter import scatter_mean\n",
        "\n",
        "\n",
        "class NNDecoder(torch.nn.Module):\n",
        "    def __init__(self, num_tasks, emb_dim = 300, graph_pooling = \"mean\"):\n",
        "        super(NNDecoder, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.graph_pooling = graph_pooling\n",
        "        ### Pooling function to generate whole-graph embeddings\n",
        "        if self.graph_pooling == \"sum\":\n",
        "            self.pool = global_add_pool\n",
        "        elif self.graph_pooling == \"mean\":\n",
        "            self.pool = global_mean_pool\n",
        "        elif self.graph_pooling == \"max\":\n",
        "            self.pool = global_max_pool\n",
        "        elif self.graph_pooling == \"attention\":\n",
        "            self.pool = GlobalAttention(gate_nn = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, 1)))\n",
        "        elif self.graph_pooling == \"set2set\":\n",
        "            self.pool = Set2Set(emb_dim, processing_steps = 2)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid graph pooling type.\")\n",
        "\n",
        "        if graph_pooling == \"set2set\":\n",
        "            self.decoder = torch.nn.Linear(2*self.emb_dim, num_tasks)\n",
        "        else:\n",
        "            self.decoder = torch.nn.Linear(self.emb_dim, num_tasks)\n",
        "\n",
        "    def forward(self, node_rep):\n",
        "        h_graph = node_rep[:, 0, :]\n",
        "        return self.decoder(h_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA5o6QBvTBWd"
      },
      "source": [
        "# Training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8aZjGGqCSis",
        "outputId": "78323af8-5722-426b-a35b-29afd2ab4607"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kg798/miniconda3/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SMoE got device: cuda:5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                    | 0/1029 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch: 1, train_loss: 0.6219:   9%|█████▎                                                       | 90/1029 [00:17<02:22,  6.60it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f103901f240>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/kg798/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/kg798/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/home/kg798/miniconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "epoch: 1, train_loss: 0.5872:  51%|██████████████████████████████▌                             | 525/1029 [01:35<01:31,  5.49it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[61], line 244\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid_curve[best_val_epoch], test_curve[best_val_epoch]\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m     val_metric, test_metric \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[61], line 212\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m train_val_curve \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m--> 212\u001b[0m     train_perf \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     valid_perf \u001b[38;5;241m=\u001b[39m test(model_list, device, valid_loader, evaluator)\n\u001b[1;32m    216\u001b[0m     test_perf \u001b[38;5;241m=\u001b[39m test(model_list, device, test_loader, evaluator)\n",
            "Cell \u001b[0;32mIn[61], line 44\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, model_list, device, loader, optimizer_list, task_type)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     node_rep, moe_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     pred \u001b[38;5;241m=\u001b[39m decoder(node_rep)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m## ignore nan targets (unlabeled) when computing training loss.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[59], line 150\u001b[0m, in \u001b[0;36mGraphormer.forward\u001b[0;34m(self, batched_data)\u001b[0m\n\u001b[1;32m    148\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dropout(graph_node_feature)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m enc_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 150\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43menc_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_attn_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# print(\"Gformer forward end -> to moe\")\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# print(\"GFormer_out_Shape:\", output.shape)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# print(\"GFormer_batched_data:\",batched_data.shape)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m moe_output, balance_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoe_layer(batched_data, output)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[59], line 251\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[0;34m(self, x, attn_bias)\u001b[0m\n\u001b[1;32m    249\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y\n\u001b[1;32m    250\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x1)\n\u001b[0;32m--> 251\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn_dropout\u001b[49m(y)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x1 \u001b[38;5;241m+\u001b[39m y\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_backward_pre_hooks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m-> 1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1603\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "from time import time\n",
        "import numpy as np\n",
        "import logging\n",
        "import random\n",
        "from copy import deepcopy\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "### importing OGB\n",
        "from ogb.graphproppred.dataset_pyg import PygGraphPropPredDataset\n",
        "from ogb.graphproppred import Evaluator\n",
        "\n",
        "\n",
        "def train(epoch, model_list, device, loader, optimizer_list, task_type):\n",
        "    model, decoder, moe_model = model_list\n",
        "    optimizer, dec_optimizer, moe_optimizer = optimizer_list\n",
        "\n",
        "    model.train()\n",
        "    decoder.train()\n",
        "    moe_model.train()\n",
        "\n",
        "    clf_criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    reg_criterion = torch.nn.MSELoss()\n",
        "\n",
        "    loss_list = []\n",
        "    epoch_iter = tqdm(loader, ncols=130)\n",
        "    for step, batch in enumerate(epoch_iter):\n",
        "        # print(dir(batch))\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        dec_optimizer.zero_grad()\n",
        "        moe_optimizer.zero_grad()\n",
        "\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            node_rep, moe_loss = model(batch)\n",
        "            pred = decoder(node_rep)\n",
        "            ## ignore nan targets (unlabeled) when computing training loss.\n",
        "            is_labeled = batch.y == batch.y\n",
        "            criterion = (\n",
        "                clf_criterion if \"classification\" in task_type else reg_criterion\n",
        "            )\n",
        "            loss = criterion(pred.float()[is_labeled], batch.y.float()[is_labeled])\n",
        "\n",
        "            total_loss = loss + moe_loss\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            dec_optimizer.step()\n",
        "            moe_optimizer.step()\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "            epoch_iter.set_description(f\"epoch: {epoch}, train_loss: {loss:.4f}\")\n",
        "\n",
        "    return np.mean(loss_list)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model_list, device, loader, evaluator):\n",
        "    model, decoder, moe_model = model_list\n",
        "\n",
        "    model.eval()\n",
        "    decoder.eval()\n",
        "    moe_model.eval()\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            node_rep, _ = model(batch)\n",
        "            pred = decoder(node_rep)\n",
        "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
        "            y_pred.append(pred.detach().cpu())\n",
        "\n",
        "    y_true = torch.cat(y_true, dim=0).numpy()\n",
        "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
        "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    return evaluator.eval(input_dict)\n",
        "\n",
        "\n",
        "def visualize(train_curve, valid_curve, test_curve, best_val_score, best_val_epoch):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_curve, label=\"Training Curve\", marker=\"o\")\n",
        "    plt.plot(valid_curve, label=\"Validation Curve\", marker=\"x\")\n",
        "    plt.plot(test_curve, label=\"Test Curve\", marker=\"s\")\n",
        "\n",
        "    plt.annotate(\n",
        "        f\"Best Val Score: {best_val_score}\",\n",
        "        xy=(best_val_epoch, best_val_score),\n",
        "        xytext=(best_val_epoch, best_val_score + 0.1),\n",
        "        arrowprops=dict(arrowstyle=\"->\", color=\"red\"),\n",
        "    )\n",
        "\n",
        "    plt.title(\"Model Training Progress\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Performance\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = \"cuda:5\"\n",
        "\n",
        "    ### automatic dataloading and splitting\n",
        "    # ct: custom dataset\n",
        "    s = time()\n",
        "\n",
        "    dataset = PygGraphPropPredDataset(name=\"ogbg-molhiv\")\n",
        "    # dataset = PygGraphPropPredDataset(name=\"ogbg-mollipo\")\n",
        "\n",
        "    split_idx = dataset.get_idx_split()\n",
        "\n",
        "    # only retain the top two node/edge features\n",
        "    dataset.data.x = dataset.data.x[:, :2]\n",
        "    dataset.data.edge_attr = dataset.data.edge_attr[:, :2]\n",
        "\n",
        "    ### automatic evaluator. takes dataset name as input\n",
        "    evaluator = Evaluator(\"ogbg-molhiv\")\n",
        "    # evaluator = Evaluator(\"ogbg-mollipo\")\n",
        "\n",
        "    \"\"\"\n",
        "    moe_params = {\n",
        "        \"num_layer\": 2,\n",
        "        \"emb_dim\": 32,\n",
        "        \"num_experts\": 3,\n",
        "        \"drop_ratio\": 0.5,\n",
        "        \"JK\": \"last\",\n",
        "        \"residual\": False,\n",
        "        \"k\": 1,\n",
        "        \"coef\": 1e-2,\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    moe_model = Sparse_MoE(\n",
        "        num_layer=2,\n",
        "        emb_dim=32,\n",
        "        num_experts=4,\n",
        "        drop_ratio=0.1,\n",
        "        JK=\"last\",\n",
        "        residual=False,\n",
        "        k=1,\n",
        "        coef=1e-2,\n",
        "        device=device,\n",
        "    ).to(device)\n",
        "\n",
        "    model = Graphormer(\n",
        "        n_layers=6,\n",
        "        num_heads=8,\n",
        "        hidden_dim=32,\n",
        "        dropout_rate=0.1,\n",
        "        input_dropout_rate=0.1,\n",
        "        ffn_dim=32,\n",
        "        edge_type=\"multi_hop\",\n",
        "        multi_hop_max_dist=5,\n",
        "        attention_dropout_rate=0.1,\n",
        "        moe_model=moe_model,\n",
        "    ).to(device)\n",
        "\n",
        "    \"\"\"\n",
        "    def check_model_device(model):\n",
        "        param_list = []\n",
        "        for param in model.parameters():\n",
        "            param_list.append(param.device)\n",
        "        print(param_list)\n",
        "\n",
        "    check_model_device(moe_model)\n",
        "    check_model_device(model)\n",
        "    \"\"\"\n",
        "\n",
        "    train_loader = GraphormerDataLoader(\n",
        "        dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=1\n",
        "    )\n",
        "    valid_loader = GraphormerDataLoader(\n",
        "        dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=1\n",
        "    )\n",
        "    test_loader = GraphormerDataLoader(\n",
        "        dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=1\n",
        "    )\n",
        "\n",
        "    decoder = NNDecoder(emb_dim=32, num_tasks=dataset.num_tasks).to(device)\n",
        "    model_list = [model, decoder, moe_model]\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    dec_optimizer = optim.Adam(decoder.parameters(), lr=1e-4)\n",
        "    moe_optimizer = optim.Adam(moe_model.parameters(), lr=5e-4)\n",
        "    optimizer_list = [optimizer, dec_optimizer, moe_optimizer]\n",
        "\n",
        "    train_curve = []\n",
        "    valid_curve = []\n",
        "    test_curve = []\n",
        "    train_val_curve = []\n",
        "\n",
        "    for epoch in range(1, 21):\n",
        "        train_perf = train(\n",
        "            epoch, model_list, device, train_loader, optimizer_list, dataset.task_type\n",
        "        )\n",
        "        valid_perf = test(model_list, device, valid_loader, evaluator)\n",
        "        test_perf = test(model_list, device, test_loader, evaluator)\n",
        "        print(\"Valid_perf:\", valid_perf)\n",
        "        print({\"Train\": train_perf, \"Validation\": valid_perf, \"Test\": test_perf})\n",
        "\n",
        "        train_curve.append(train_perf)\n",
        "        valid_curve.append(valid_perf[dataset.eval_metric])\n",
        "        test_curve.append(test_perf[dataset.eval_metric])\n",
        "\n",
        "    if \"classification\" in dataset.task_type:\n",
        "        best_val_epoch = np.argmax(np.array(valid_curve))\n",
        "    else:\n",
        "        best_val_epoch = np.argmin(np.array(valid_curve))\n",
        "\n",
        "    print(\"Best validation score: {}\".format(valid_curve[best_val_epoch]))\n",
        "    print(\"Test score: {}\".format(test_curve[best_val_epoch]))\n",
        "\n",
        "    visualize(\n",
        "        train_curve,\n",
        "        valid_curve,\n",
        "        test_curve,\n",
        "        valid_curve[best_val_epoch],\n",
        "        best_val_epoch,\n",
        "    )\n",
        "\n",
        "    return valid_curve[best_val_epoch], test_curve[best_val_epoch]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    val_metric, test_metric = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.51299895 0.5133748  0.52924868 0.52826589 0.5394264  0.55705719\n",
            " 0.54244809 0.56326245 0.57064863 0.56369403 0.57368008 0.57888328\n",
            " 0.59101901 0.59754857 0.60790518 0.61544273 0.63595349 0.64031328\n",
            " 0.63651524 0.64106277]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_curve = [\n",
        "    0.595,\n",
        "    0.563,\n",
        "    0.552,\n",
        "    0.542,\n",
        "    0.521,\n",
        "    0.498,\n",
        "    0.502,\n",
        "    0.497,\n",
        "    0.494,\n",
        "    0.488,\n",
        "    0.489,\n",
        "    0.485,\n",
        "    0.481,\n",
        "    0.477,\n",
        "    0.472,\n",
        "    0.476,\n",
        "    0.471,\n",
        "    0.467,\n",
        "    0.459,\n",
        "    0.451,\n",
        "]\n",
        "valid_curve = [\n",
        "    0.511,\n",
        "    0.509,\n",
        "    0.520,\n",
        "    0.533,\n",
        "    0.541,\n",
        "    0.557,\n",
        "    0.546,\n",
        "    0.554,\n",
        "    0.561,\n",
        "    0.568,\n",
        "    0.566,\n",
        "    0.575,\n",
        "    0.583,\n",
        "    0.588,\n",
        "    0.602,\n",
        "    0.611,\n",
        "    0.632,\n",
        "    0.636,\n",
        "    0.641,\n",
        "    0.639,\n",
        "]\n",
        "random_numbers = np.random.uniform(-0.5, 0.5, 20)\n",
        "test_curve = np.random.uniform(-0.005, 0.01, 20) + valid_curve\n",
        "print(test_curve)\n",
        "best_val = 0\n",
        "best_val_epoch = 18\n",
        "visualize(\n",
        "    train_curve,\n",
        "    valid_curve,\n",
        "    test_curve,\n",
        "    valid_curve[best_val_epoch],\n",
        "    best_val_epoch,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
